{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert a Python list into a PySpark DataFrame, use spark.createDataFrame() or convert it to an RDD first. Here's how:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"ListToDataFrame\").getOrCreate()\n",
    "\n",
    "# Python list\n",
    "ls = [1, 2, 3, 5, 4, 7]\n",
    "\n",
    "# Convert each element to a list (for row structure)\n",
    "ls2 = [[i] for i in ls]\n",
    "\n",
    "# Correct way: Pass ls2 directly\n",
    "df = spark.createDataFrame(ls2, [\"number\"])\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert the dictionary d = {1: \"Tom\", 2: \"Brad\", 3: \"Joe\"} into a PySpark DataFrame, follow these steps:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DictToDataFrame\").getOrCreate()\n",
    "\n",
    "# Dictionary\n",
    "d = {1: \"Tom\", 2: \"Brad\", 3: \"Joe\"}\n",
    "\n",
    "# Convert dictionary to list of tuples\n",
    "ls = list(d.items())  # [(1, 'Tom'), (2, 'Brad'), (3, 'Joe')]\n",
    "\n",
    "# Create DataFrame with column names\n",
    "df = spark.createDataFrame(ls, [\"ID\", \"Name\"])\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert a list of tuples like ls = [(1, 3), (1, 4), (1, 5)] into a PySpark DataFrame, define column names during the conversion.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"TupleListToDataFrame\").getOrCreate()\n",
    "\n",
    "# List of tuples\n",
    "ls = [(1, 3), (1, 4), (1, 5)]\n",
    "\n",
    "# Convert list to DataFrame with column names\n",
    "df = spark.createDataFrame(ls, [\"col1\", \"col2\"])\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
