{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime\n",
    "\n",
    "def greet():\n",
    "    print(\"Hello, Airflow!\")\n",
    "\n",
    "default_args = {\n",
    "    \"start_date\": datetime(2024, 1, 1),\n",
    "    \"catchup\": False\n",
    "}\n",
    "\n",
    "with DAG(\"hello_airflow\", default_args=default_args, schedule_interval=\"@daily\") as dag:\n",
    "    task1 = PythonOperator(\n",
    "        task_id=\"say_hello\",\n",
    "        python_callable=greet\n",
    "    )\n",
    "\n",
    "task1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ETL DAG\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.postgres.operators.postgres import PostgresOperator\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Default args\n",
    "default_args = {\n",
    "    \"owner\": \"airflow\",\n",
    "    \"start_date\": datetime(2024, 1, 1),\n",
    "    \"retries\": 1,\n",
    "    \"retry_delay\": timedelta(minutes=5),\n",
    "    \"catchup\": False\n",
    "}\n",
    "\n",
    "# Function to extract data\n",
    "def extract():\n",
    "    url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"/tmp/posts.csv\", index=False)\n",
    "\n",
    "# Function to transform data\n",
    "def transform():\n",
    "    df = pd.read_csv(\"/tmp/posts.csv\")\n",
    "    df[\"title\"] = df[\"title\"].str.upper()\n",
    "    df.to_csv(\"/tmp/posts_transformed.csv\", index=False)\n",
    "\n",
    "# Function to load data into PostgreSQL\n",
    "def load():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"your_database\",\n",
    "        user=\"your_user\",\n",
    "        password=\"your_password\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    df = pd.read_csv(\"/tmp/posts_transformed.csv\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO posts (id, user_id, title, body) VALUES (%s, %s, %s, %s)\",\n",
    "            (row[\"id\"], row[\"userId\"], row[\"title\"], row[\"body\"])\n",
    "        )\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Define DAG\n",
    "with DAG(\"etl_pipeline\", default_args=default_args, schedule_interval=\"@daily\") as dag:\n",
    "    \n",
    "    create_table = PostgresOperator(\n",
    "        task_id=\"create_table\",\n",
    "        postgres_conn_id=\"postgres_local\",\n",
    "        sql=\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS posts (\n",
    "            id INT PRIMARY KEY,\n",
    "            user_id INT,\n",
    "            title TEXT,\n",
    "            body TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    extract_task = PythonOperator(task_id=\"extract\", python_callable=extract)\n",
    "    transform_task = PythonOperator(task_id=\"transform\", python_callable=transform)\n",
    "    load_task = PythonOperator(task_id=\"load\", python_callable=load)\n",
    "\n",
    "    create_table >> extract_task >> transform_task >> load_task\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
